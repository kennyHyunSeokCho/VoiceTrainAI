Overview
This product is an AI-powered vocal training mobile application that allows users to build their own personalized voice models and receive pitch-based feedback on singing performances. It targets individuals seeking to improve their vocal skills—ranging from casual learners to serious vocal trainees—by providing personalized feedback using advanced machine learning technologies. The app addresses the lack of real-time, user-specific vocal training tools in the current market and provides a more engaging, accessible, and personalized experience compared to traditional voice coaching.

Core Features
Personal Voice Model Generation (RVC V2-based)

What it does: Allows users to record a few minutes of their own voice to generate a personalized voice model.

Why it's important: Enables customized training by using the user's own voice to synthesize songs and identify pitch issues.

How it works: Users record 3–5 minutes of clean voice data, which is processed to extract pitch (f0) and content features. These features are used to train an RVC V2 model, which is saved for inference use.

Song Import and Voice Replacement Option

What it does: Lets users choose a song and decide between listening to the original version or a version where their personal voice model replaces the original vocals.

Why it's important: Provides a clear and engaging method for users to evaluate their own voice performance relative to the original singer.

How it works: Upon song selection, the app separates the vocal and instrumental tracks. The user’s voice model is applied to generate a personalized version. Both options are presented for playback.

Real-Time Pitch Visualization and Comparison

What it does: Displays a karaoke-style interface showing the correct pitch and the user's real-time pitch input.

Why it's important: Helps users visually understand pitch accuracy and timing in real time.

How it works: The application extracts the pitch curve of the original track. While the user sings, their pitch is extracted using lightweight pitch detection algorithms and overlaid for comparison.

LLM-Based Vocal Performance Feedback

What it does: Provides natural language feedback on the user’s vocal performance after the song ends, highlighting areas for improvement.

Why it's important: Offers actionable, human-readable feedback that helps users identify and focus on weak spots such as breath control or pitch stability.

How it works: After the session, the app analyzes pitch deviations and vocal issues, structures them into a data format, and sends them to an LLM for personalized feedback generation.

Authentication via KakaoTalk or SMS

What it does: Allows users to sign up using KakaoTalk or mobile phone number verification.

Why it's important: Ensures secure access and allows the app to store user-specific data and voice models.

How it works: Integrates Kakao login SDK or third-party SMS verification API to authenticate and register users.

User Experience
User Personas
Casual Singers: Individuals who enjoy singing and want light feedback or entertainment.

Hobby Vocalists: Users who are actively trying to improve their vocal performance.

Aspiring Professionals: Serious trainees who need structured, data-backed feedback for improvement.

Key User Flows
User signs up using KakaoTalk or SMS verification.

User records voice and generates a personal voice model.

User selects a song and chooses between original and synthesized voice.

User sings along with the karaoke-style pitch UI.

After singing, user receives LLM-generated feedback based on performance.

UI/UX Considerations
Karaoke-style UI with clearly distinguished pitch lines for original and user input.

Loading and progress indicators during voice model training.

Clear visualization of feedback and performance breakdown.

Lightweight and responsive mobile interface built for cross-platform use.

PRD
Technical Architecture
System Components
Frontend: Flutter-based mobile application for iOS and Android

Backend: RESTful API using FastAPI with WebSocket support for real-time features

Model Server: RVC V2 server for training and inference

Pitch Analysis Engine: Real-time pitch extraction using CREPE or YIN

LLM Server: GPT-3.5 or local LLM to generate performance feedback

Authentication Service: Kakao SDK and/or third-party SMS API

Storage: AWS S3 for audio/model assets, PostgreSQL or Firebase for metadata

Data Models
User: user_id, nickname, phone_number, voice_model_url, registered_at

Song: song_id, title, artist, pitch_data[], instrumental_url

Session: session_id, user_id, song_id, pitch_score, feedback_text, created_at

APIs and Integrations
POST /auth/kakao or /auth/sms – user authentication

POST /recordings/upload – upload user voice data

POST /model/train – trigger RVC model training

POST /model/infer – generate user-voice version of a song

POST /singing/session – store pitch comparison results

POST /feedback/generate – send singing data to LLM and get feedback

Infrastructure Requirements
GPU-enabled server for RVC model training (e.g., RTX 4090)

Low-latency audio processing backend

Scalable storage and CDN for audio files

Load-balanced API services with real-time WebSocket handling

Development Roadmap
Phase 1 – MVP
KakaoTalk/SMS-based user authentication

Voice recording and model generation via RVC V2

Song upload and vocal separation

Basic karaoke UI with real-time pitch comparison

Rule-based feedback placeholder (non-LLM)

Phase 2 – Enhanced Features
Integration with LLM for personalized feedback

Vocal performance analytics (e.g., heatmaps, pitch scores)

UI/UX polish for mobile performance and accessibility

Phase 3 – Community and Expansion
Social sharing of user-generated covers

Leaderboards or challenge modes

Subscription model for premium features or songs

Logical Dependency Chain
User authentication is the foundation for managing personal data and voice models.

Voice recording and RVC model training must be operational before voice synthesis.

Song selection and synthesis build upon the trained voice model.

Real-time pitch UI must follow for interaction.

LLM feedback is built after core performance data is captured and structured.


Risks and Mitigations
Model Training Latency
Training the RVC model may require a few minutes, which can lead to user drop-off or confusion.
Mitigation: Use asynchronous processing and implement a user notification system that informs users when training is complete.

Pitch Extraction Accuracy
Real-time pitch extraction may vary depending on the device's microphone quality and processing power.
Mitigation: Use lightweight and reliable pitch detection models such as CREPE, and optimize for mobile performance.

High Cost of LLM Usage
Frequent calls to the LLM for feedback generation can incur high operational costs, especially if using GPT-4o.
Mitigation: Use OpenAI’s GPT-4o efficiently by compressing input data and prompts. For cost-saving purposes, consider batching requests or implementing a feedback quota system for free-tier users.

Third-Party Authentication Service Reliability
Services like KakaoTalk or SMS-based authentication may experience outages or API limitations.
Mitigation: Provide fallback login options such as email/password authentication or OAuth with other providers.


Appendix
Research Findings
Karaoke apps lack personalized voice synthesis and intelligent feedback.

RVC V2 has been proven to generate high-quality voice models with limited data.

LLMs like GPT-4o can effectively summarize technical performance metrics into human-friendly advice.

Technical Specifications
Mobile Framework: Flutter

Backend: FastAPI, PostgreSQL, WebSocket

ML Frameworks: PyTorch (RVC V2), TensorFlow or ONNX (CREPE)

LLM: OpenAI GPT-4o or fine-tuned llama3 via local API

Audio Tools: ffmpeg, demucs, librosa

