"""
ğŸµ ë³´ì»¬ ë¶„ë¦¬ ì•Œê³ ë¦¬ì¦˜ ëª¨ë“ˆ (Demucs ì‚¬ìš©)
Demucsë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì•… íŒŒì¼ì—ì„œ ë³´ì»¬ê³¼ ë°˜ì£¼ë¥¼ ë¶„ë¦¬í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import librosa
import numpy as np
import torch
import torchaudio
from demucs import pretrained
from demucs.apply import apply_model
from demucs.audio import convert_audio

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class VocalSeparator:
    """
    ë³´ì»¬ ë¶„ë¦¬ í´ë˜ìŠ¤ (Demucs ê¸°ë°˜)
    
    Demucs ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìŒì•… íŒŒì¼ì—ì„œ ë³´ì»¬ê³¼ ë°˜ì£¼ë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    ì§€ì›í•˜ëŠ” ëª¨ë¸:
    - htdemucs: ê¸°ë³¸ 4-source ë¶„ë¦¬ (ë³´ì»¬, ë“œëŸ¼, ë² ì´ìŠ¤, ê¸°íƒ€)
    - htdemucs_ft: íŒŒì¸íŠœë‹ëœ ë²„ì „
    - hdemucs_mmi: ë³´ì»¬ í’ˆì§ˆì— ìµœì í™”
    """
    
    def __init__(self, model_name: str = "htdemucs"):
        """
        ë³´ì»¬ ë¶„ë¦¬ê¸° ì´ˆê¸°í™”
        
        Args:
            model_name (str): ì‚¬ìš©í•  Demucs ëª¨ë¸ ì´ë¦„
                - "htdemucs": ê¸°ë³¸ 4-source ë¶„ë¦¬ (ì¶”ì²œ)
                - "htdemucs_ft": íŒŒì¸íŠœë‹ëœ ë²„ì „
                - "hdemucs_mmi": ë³´ì»¬ í’ˆì§ˆ ìš°ì„ 
        """
        self.model_name = model_name
        self.model = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # ëª¨ë¸ ë¡œë“œ
        self._load_model()
    
    def _load_model(self) -> None:
        """
        Demucs ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        ì²« ë²ˆì§¸ ì‹¤í–‰ ì‹œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ë¯€ë¡œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """
        try:
            logger.info(f"ğŸµ {self.model_name} ëª¨ë¸ ë¡œë“œ ì¤‘... (ë””ë°”ì´ìŠ¤: {self.device})")
            self.model = pretrained.get_model(self.model_name)
            self.model.to(self.device)
            logger.info("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def separate_audio(self, 
                      input_path: str,
                      output_dir: str,
                      audio_format: str = "wav") -> Dict[str, str]:
        """
        ìŒì•… íŒŒì¼ì—ì„œ ë³´ì»¬ê³¼ ë°˜ì£¼ë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            input_path (str): ì…ë ¥ ìŒì•… íŒŒì¼ ê²½ë¡œ
            output_dir (str): ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            audio_format (str): ì¶œë ¥ ì˜¤ë””ì˜¤ í¬ë§· (wav, mp3, flac ë“±)
        
        Returns:
            Dict[str, str]: ë¶„ë¦¬ëœ ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ì˜ ê²½ë¡œ
                - "vocal": ë³´ì»¬ íŒŒì¼ ê²½ë¡œ
                - "inst": ë°˜ì£¼(instrumental) íŒŒì¼ ê²½ë¡œ
        
        Raises:
            FileNotFoundError: ì…ë ¥ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì„ ë•Œ
            Exception: ë¶„ë¦¬ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ ì‹œ
        """
        # ì…ë ¥ íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(input_path):
            raise FileNotFoundError(f"ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        try:
            logger.info(f"ğŸ§ ìŒì„± ë¶„ë¦¬ ì‹œì‘: {input_path}")
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
            wav, sr = torchaudio.load(input_path)
            logger.info(f"ğŸ“Š ì›ë³¸ ì˜¤ë””ì˜¤: {wav.shape}, {sr}Hz")
            
            # ëª¨ë¸ì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            wav = convert_audio(wav, sr, self.model.samplerate, self.model.audio_channels)
            wav = wav.to(self.device)
            
            # ë³´ì»¬/ì•…ê¸° ë¶„ë¦¬ ì‹¤í–‰
            with torch.no_grad():
                sources = apply_model(
                    self.model, 
                    wav[None], 
                    split=True,  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•œ ì²­í¬ ë¶„í• 
                    overlap=0.25  # ì²­í¬ ê°„ ì˜¤ë²„ë©
                )[0]
            
            # ê²°ê³¼ íŒŒì¼ ì €ì¥ (ë³´ì»¬ê³¼ ë°˜ì£¼ë§Œ)
            result_paths = {}
            base_filename = Path(input_path).stem
            
            # Demucs ëª¨ë¸ì˜ source ì´ë¦„ë“¤
            source_names = self.model.sources
            
            # ë³´ì»¬ ì°¾ê¸° ë° ì €ì¥
            if "vocals" in source_names:
                vocal_idx = source_names.index("vocals")
                
                # 1. ë³´ì»¬ íŒŒì¼ ì €ì¥
                vocal_filename = f"{base_filename}_vocal.{audio_format}"
                vocal_path = output_path / vocal_filename
                
                torchaudio.save(
                    str(vocal_path),
                    sources[vocal_idx].cpu(),
                    self.model.samplerate,
                    format=audio_format.upper() if audio_format != "mp3" else None
                )
                
                result_paths["vocal"] = str(vocal_path)
                logger.info(f"âœ… ë³´ì»¬ ì €ì¥ ì™„ë£Œ: {vocal_path}")
                
                # 2. ë°˜ì£¼ (ë³´ì»¬ ì œì™¸í•œ ëª¨ë“  ê²ƒ) ìƒì„± ë° ì €ì¥
                accompaniment = torch.sum(
                    torch.stack([sources[i] for i in range(len(sources)) if i != vocal_idx]), 
                    dim=0
                )
                
                inst_filename = f"{base_filename}_inst.{audio_format}"
                inst_path = output_path / inst_filename
                
                torchaudio.save(
                    str(inst_path),
                    accompaniment.cpu(),
                    self.model.samplerate,
                    format=audio_format.upper() if audio_format != "mp3" else None
                )
                
                result_paths["inst"] = str(inst_path)
                logger.info(f"âœ… ë°˜ì£¼ ì €ì¥ ì™„ë£Œ: {inst_path}")
            else:
                logger.error("âŒ ë³´ì»¬ íŠ¸ë™ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                raise Exception("ëª¨ë¸ì—ì„œ ë³´ì»¬ íŠ¸ë™ì„ ë¶„ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            logger.info(f"ğŸ‰ ë³´ì»¬ ë¶„ë¦¬ ì™„ë£Œ! ì´ {len(result_paths)}ê°œ íŒŒì¼ ìƒì„±")
            return result_paths
            
        except Exception as e:
            logger.error(f"âŒ ë³´ì»¬ ë¶„ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    def _get_korean_instrument_name(self, instrument: str) -> str:
        """
        ì˜ì–´ ì•…ê¸°ëª…ì„ í•œê¸€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            instrument (str): ì˜ì–´ ì•…ê¸°ëª…
            
        Returns:
            str: í•œê¸€ ì•…ê¸°ëª…
        """
        instrument_mapping = {
            "vocals": "ë³´ì»¬",
            "drums": "ë“œëŸ¼",
            "bass": "ë² ì´ìŠ¤",
            "other": "ê¸°íƒ€ì•…ê¸°",
            "accompaniment": "ë°˜ì£¼"
        }
        return instrument_mapping.get(instrument, instrument)
    
    def get_audio_info(self, audio_path: str) -> Dict[str, any]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            audio_path (str): ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict[str, any]: ì˜¤ë””ì˜¤ ì •ë³´
                - duration: ì¬ìƒ ì‹œê°„(ì´ˆ)
                - sample_rate: ìƒ˜í”Œ ë ˆì´íŠ¸
                - channels: ì±„ë„ ìˆ˜
                - file_size: íŒŒì¼ í¬ê¸°(bytes)
        """
        try:
            # torchaudioë¡œ ì˜¤ë””ì˜¤ ì •ë³´ ì¶”ì¶œ
            wav, sr = torchaudio.load(audio_path)
            
            return {
                "duration": float(wav.shape[-1] / sr),
                "sample_rate": int(sr),
                "channels": int(wav.shape[0]),
                "file_size": os.path.getsize(audio_path),
                "format": Path(audio_path).suffix.lower(),
                "device_used": self.device
            }
        except Exception as e:
            logger.error(f"âŒ ì˜¤ë””ì˜¤ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            raise
    
    def get_available_models(self) -> List[str]:
        """
        ì‚¬ìš© ê°€ëŠ¥í•œ Demucs ëª¨ë¸ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            List[str]: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì´ë¦„ë“¤
        """
        try:
            return pretrained.list_models()
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return ["htdemucs", "htdemucs_ft", "hdemucs_mmi"]  # ê¸°ë³¸ ëª©ë¡

# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_vocal_separation():
    """
    ë³´ì»¬ ë¶„ë¦¬ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” í•¨ìˆ˜
    """
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ (ì‹¤ì œ íŒŒì¼ë¡œ êµì²´ í•„ìš”)
    test_input = "test_audio.mp3"  # í…ŒìŠ¤íŠ¸ìš© ìŒì•… íŒŒì¼
    test_output = "output"  # ì¶œë ¥ ë””ë ‰í† ë¦¬
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not os.path.exists(test_input):
        print(f"âš ï¸ í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {test_input}")
        print("ì‹¤ì œ ìŒì•… íŒŒì¼ì„ ì¤€ë¹„í•˜ê³  ê²½ë¡œë¥¼ ìˆ˜ì •í•´ì£¼ì„¸ìš”.")
        return
    
    try:
        # ë³´ì»¬ ë¶„ë¦¬ê¸° ìƒì„±
        separator = VocalSeparator("htdemucs")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì¶œë ¥
        models = separator.get_available_models()
        print(f"ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤: {models}")
        
        # ì˜¤ë””ì˜¤ ì •ë³´ ì¶œë ¥
        audio_info = separator.get_audio_info(test_input)
        print(f"ğŸ“Š ì˜¤ë””ì˜¤ ì •ë³´:")
        print(f"   ì¬ìƒì‹œê°„: {audio_info['duration']:.2f}ì´ˆ")
        print(f"   ìƒ˜í”Œë ˆì´íŠ¸: {audio_info['sample_rate']:,}Hz")
        print(f"   ì±„ë„: {audio_info['channels']}")
        print(f"   íŒŒì¼í¬ê¸°: {audio_info['file_size']:,} bytes")
        print(f"   ì²˜ë¦¬ ë””ë°”ì´ìŠ¤: {audio_info['device_used']}")
        
        # ë³´ì»¬ ë¶„ë¦¬ ì‹¤í–‰
        result = separator.separate_audio(test_input, test_output)
        
        print(f"\nğŸµ ë¶„ë¦¬ ê²°ê³¼:")
        for instrument, path in result.items():
            file_size = os.path.getsize(path)
            print(f"   {instrument}: {path} ({file_size:,} bytes)")
            
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    """
    ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ í˜¸ì¶œ
    """
    print("ğŸµ ë³´ì»¬ ë¶„ë¦¬ ì•Œê³ ë¦¬ì¦˜ í…ŒìŠ¤íŠ¸ ì‹œì‘ (Demucs)")
    test_vocal_separation() 